{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast  # For safely evaluating array-like strings\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def clean_data(df, folder_name):\n",
    "    \"\"\"\n",
    "    Perform data cleaning based on folder-specific requirements.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to clean.\n",
    "    folder_name (str): The name of the folder to apply specific cleaning rules.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # General cleaning logic\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Apply folder-specific cleaning logic\n",
    "    if folder_name == \"080_Books\":\n",
    "        columns_fill_zero = ['Copies Left', 'Wished Users', 'Reviews']\n",
    "        df[columns_fill_zero] = df[columns_fill_zero].fillna(0)\n",
    "        numerical_columns = ['Ratings']\n",
    "        df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].median())\n",
    "        categorical_columns = ['Publication']\n",
    "        df[categorical_columns] = df[categorical_columns].fillna('Unknown')\n",
    "        text_columns = ['Book Title', 'Author', 'Category', 'Stock Status', 'Edition', 'Publication']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "        df['Price (TK)'] = pd.to_numeric(df['Price (TK)'], errors='coerce')\n",
    "\n",
    "    elif folder_name == \"079_Coffee\":\n",
    "        text_columns = ['store_location', 'product_category', 'product_type', 'product_detail', 'Month_1', 'Weekday_1']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "        df['Revenue'] = df['Revenue'].astype(str).str.replace(',', '.').str.strip()\n",
    "        numeric_columns = ['transaction_qty', 'unit_price']\n",
    "        df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    elif folder_name == \"078_Fires\":\n",
    "        text_columns = ['calendar_names_1', 'calendar_names_2', 'calendar_1', 'calendar_2']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "        numeric_columns = ['area', 'DMC', 'DC', 'temp', 'ISI', 'wind']\n",
    "        df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    elif folder_name == \"076_NBA\":\n",
    "        text_columns = ['Season_type', 'PLAYER', 'TEAM']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "    elif folder_name == \"075_Mortality\":\n",
    "        text_columns = ['Region', 'Status', 'Sex', 'Cause']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "    elif folder_name == \"074_Lift\":\n",
    "        text_columns = ['Lifter Name', 'Weight Class', 'Lift Type']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "    # Add other folder-specific cleaning logic here\n",
    "    # Folder-specific cleaning logic\n",
    "# Folder-specific cleaning logic\n",
    "    elif folder_name == \"071_COL\":\n",
    "        text_columns = ['Country']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "    # Apply folder-specific cleaning logic\n",
    "    elif folder_name == \"070_OpenFoodFacts\":\n",
    "        # Handle Missing Values\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                df[col] = df[col].fillna(\"unknown\")\n",
    "            else:\n",
    "                df[col] = df[col].fillna(0)\n",
    "\n",
    "        # Standardize Text Data\n",
    "        object_columns = df.select_dtypes(include=[\"object\"]).columns\n",
    "        for col in object_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "        # Handle Array-Like Data\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                def process_array(value):\n",
    "                    try:\n",
    "                        array = ast.literal_eval(value)\n",
    "                        if isinstance(array, list):\n",
    "                            if not array:\n",
    "                                return [\"unknown\"]\n",
    "                            return [str(item).lower().strip() if isinstance(item, str) else item for item in array]\n",
    "                        else:\n",
    "                            return value\n",
    "                    except (ValueError, SyntaxError):\n",
    "                        return value\n",
    "                df[col] = df[col].apply(process_array)\n",
    "\n",
    "        # Ensure Correct Data Types\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                try:\n",
    "                    df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        # Process Specific Columns\n",
    "        def process_column(entry):\n",
    "            if isinstance(entry, list):\n",
    "                return [item.strip().lower() for item in entry if isinstance(item, str)]\n",
    "            elif isinstance(entry, str):\n",
    "                entry = entry.strip('[]')  # Remove the outer brackets\n",
    "                return [item.strip().lower() for item in entry.split(',') if item.strip()]\n",
    "            else:\n",
    "                return entry\n",
    "\n",
    "        columns_to_process = [\n",
    "            'categories_en', 'states_en', 'brands', 'labels_en', 'stores',\n",
    "            'countries_en', 'ingredients_analysis_tags', 'ingredients_tags'\n",
    "        ]\n",
    "\n",
    "        for column in columns_to_process:\n",
    "            if column in df.columns:\n",
    "                df[column] = df[column].apply(process_column)\n",
    "\n",
    "    elif folder_name == \"069_Taxonomy\":\n",
    "        df.drop(columns=['Unnamed: 7'], inplace=True, errors='ignore')\n",
    "        df.dropna(subset=['Unique ID', 'Parent'], inplace=True)\n",
    "        for column in ['Tier 2', 'Tier 3', 'Tier 4']:\n",
    "            if column in df.columns and pd.api.types.is_categorical_dtype(df[column]):\n",
    "                df[column] = df[column].cat.add_categories('Unknown')\n",
    "                df[column] = df[column].fillna('Unknown')\n",
    "\n",
    "        text_columns = ['Name', 'Tier 1', 'Tier 2', 'Tier 3', 'Tier 4']\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "    elif folder_name == \"068_WorldBank_Awards\":\n",
    "        # Ensure the 'Procurement Method' column is handled as a categorical column\n",
    "        if 'Procurement Method' in df.columns:\n",
    "            if pd.api.types.is_categorical_dtype(df['Procurement Method']):\n",
    "                 # Add 'Unknown' category if not already present\n",
    "                 if 'Unknown' not in df['Procurement Method'].cat.categories:\n",
    "                      df['Procurement Method'] = df['Procurement Method'].cat.add_categories('Unknown')\n",
    "            df['Procurement Method'] = df['Procurement Method'].fillna('Unknown')\n",
    "\n",
    "        # Ensure 'Project Global Practice' column is handled as a categorical column\n",
    "        if 'Project Global Practice' in df.columns:\n",
    "            if pd.api.types.is_categorical_dtype(df['Project Global Practice']):\n",
    "                # Add 'Not Specified' category if not already present\n",
    "                if 'Not Specified' not in df['Project Global Practice'].cat.categories:\n",
    "                     df['Project Global Practice'] = df['Project Global Practice'].cat.add_categories('Not Specified')\n",
    "            df['Project Global Practice'] = df['Project Global Practice'].fillna('Not Specified')\n",
    "\n",
    "        \n",
    "        if 'Borrower Contract Reference Number' in df.columns:\n",
    "            df['Borrower Contract Reference Number'] = df['Borrower Contract Reference Number'].cat.add_categories('N/A')\n",
    "            df['Borrower Contract Reference Number'] = df['Borrower Contract Reference Number'].fillna('N/A')\n",
    "\n",
    "        df['Supplier ID'] = df['Supplier ID'].fillna(-1)\n",
    "        df['Contract Description'] = df['Contract Description'].fillna('No Description Provided')\n",
    "        if 'Supplier Country Code' in df.columns:\n",
    "            df['Supplier Country Code'] = df['Supplier Country Code'].cat.add_categories('Unknown')\n",
    "            df['Supplier Country Code'] = df['Supplier Country Code'].fillna('Unknown')\n",
    "\n",
    "        if 'Supplier Country' in df.columns and pd.api.types.is_categorical_dtype(df['Supplier Country']):\n",
    "             df['Supplier Country'] = df['Supplier Country'].cat.add_categories('Unknown')\n",
    "             df['Supplier Country'] = df['Supplier Country'].fillna('Unknown')\n",
    "\n",
    "        if 'Supplier' in df.columns and pd.api.types.is_categorical_dtype(df['Supplier']):\n",
    "             df['Supplier'] = df['Supplier'].cat.add_categories('Unknown Supplier')\n",
    "             df['Supplier'] = df['Supplier'].fillna('Unknown Supplier')\n",
    "\n",
    "        df.drop(columns=['Borrower Country Code'], inplace=True, errors='ignore')\n",
    "        text_columns = [\n",
    "            'Procurement Method', 'Project Global Practice', 'Contract Description',\n",
    "            'Supplier Country Code', 'Borrower Country', 'Region',\n",
    "            'Supplier Country', 'Supplier', 'Project Name'\n",
    "        ]\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "        df['Region'] = df['Region'].str.replace('_', ' ')\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "    elif folder_name == \"067_TripAdvisor\":\n",
    "        def process_text(text):\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            #stemmer = PorterStemmer() ####### Bad dite paren\n",
    "            text = text.lower().strip()\n",
    "            tokens = word_tokenize(text)\n",
    "            return \" \".join([\n",
    "                lemmatizer.lemmatize(token)  # Only lemmatize the tokens\n",
    "                #stemmer.stem(lemmatizer.lemmatize(token))\n",
    "                for token in tokens if token not in ENGLISH_STOP_WORDS\n",
    "            ])\n",
    "        \n",
    "        # Ensure 'date_stayed' is processed correctly\n",
    "        if 'date_stayed' in df.columns:\n",
    "            if pd.api.types.is_categorical_dtype(df['date_stayed']):\n",
    "                df['date_stayed'] = df['date_stayed'].cat.add_categories(['Unknown'])\n",
    "            df['date_stayed'] = df['date_stayed'].fillna('Unknown')\n",
    "        \n",
    "        # Process other text columns\n",
    "        if 'title' in df.columns:\n",
    "            df['title'] = df['title'].astype(str).fillna(\"\").str.lower().str.strip()\n",
    "\n",
    "        if 'ratings' in df.columns:\n",
    "            df['ratings'] = df['ratings'].apply(lambda x: x.lower().strip() if isinstance(x, str) else x)\n",
    "        if 'text' in df.columns:\n",
    "            df['text'] = df['text'].apply(process_text)\n",
    "\n",
    "    elif folder_name == \"066_IBM_HR\":\n",
    "        text_columns = df.select_dtypes(include=['object']).columns\n",
    "        for col in text_columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "    # Add other folder-specific cleaning logic here\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_parquet_files(base_folder):\n",
    "    \"\"\"\n",
    "    Process parquet files for each folder: read, clean, and save as CSV.\n",
    "\n",
    "    Parameters:\n",
    "    base_folder (str): Path to the competition folder.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for folder_name in os.listdir(base_folder):\n",
    "        folder_path = os.path.join(base_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"Processing folder: {folder_name}\")\n",
    "            \n",
    "            # Process 'all.parquet'\n",
    "            all_parquet_path = os.path.join(folder_path, \"all.parquet\")\n",
    "            all_csv_path = os.path.join(folder_path, \"cleaned_all.csv\")\n",
    "            if os.path.exists(all_parquet_path):\n",
    "                all_df = pd.read_parquet(all_parquet_path)\n",
    "                cleaned_all_df = clean_data(all_df, folder_name)\n",
    "                cleaned_all_df.to_csv(all_csv_path, index=False)\n",
    "                print(f\"Processed and saved: {all_csv_path}\")\n",
    "            \n",
    "            # Process 'sample.parquet'\n",
    "            sample_parquet_path = os.path.join(folder_path, \"sample.parquet\")\n",
    "            sample_csv_path = os.path.join(folder_path, \"cleaned_sample.csv\")\n",
    "            if os.path.exists(sample_parquet_path):\n",
    "                sample_df = pd.read_parquet(sample_parquet_path)\n",
    "                cleaned_sample_df = clean_data(sample_df, folder_name)\n",
    "                cleaned_sample_df.to_csv(sample_csv_path, index=False)\n",
    "                print(f\"Processed and saved: {sample_csv_path}\")\n",
    "\n",
    "# Usage\n",
    "base_folder = r\"C:\\Users\\ASUS\\Downloads\\competition\\competition\" # Replace with your actual path\n",
    "process_parquet_files(base_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUET (score-10.74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T11:07:14.328752Z",
     "iopub.status.busy": "2025-02-01T11:07:14.328369Z",
     "iopub.status.idle": "2025-02-01T11:08:54.761686Z",
     "shell.execute_reply": "2025-02-01T11:08:54.760900Z",
     "shell.execute_reply.started": "2025-02-01T11:07:14.328726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loading enhanced QA pipeline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feabea9bacb1410cb294bc0b6af91e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/540 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609f042ce6ad4e078263f5e7dccb613b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-large-uncased-whole-word-masking-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90aabc6666074a38b9aab867b8fe957f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/19.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce255e4a80684c8eb0ea15883d581d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d1a9bf2cc642a0a8f69f969e6904d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cec4bcbc514a99b015ce36b0d3b264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archive created successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "import torch\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import zipfile\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "DEVICE = 0 if torch.cuda.is_available() else -1\n",
    "MODEL_NAME = \"deepset/bert-large-uncased-whole-word-masking-squad2\"  # Larger model\n",
    "DATA_DIR = \"/kaggle/input/d/muhammedjunayed/competition-csv/competition_csv/competition\"\n",
    "QA_FILE = os.path.join(DATA_DIR, \"test_qa.csv\")\n",
    "\n",
    "# Set up advanced logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "print(\"✅ Loading enhanced QA pipeline...\")\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\", \n",
    "    model=MODEL_NAME,\n",
    "    tokenizer=MODEL_NAME,\n",
    "    device=DEVICE,\n",
    "    max_seq_len=512,\n",
    "    doc_stride=128\n",
    ")\n",
    "\n",
    "# ========== ENHANCED TEXT PROCESSING ==========\n",
    "class SemanticColumnMatcher:\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.column_vectors = self.vectorizer.fit_transform(\n",
    "            [self._preprocess(col) for col in columns]\n",
    "        )\n",
    "    \n",
    "    def _preprocess(self, text):\n",
    "        return re.sub(r'[^\\w\\s]', '', str(text).lower())\n",
    "    \n",
    "    def best_match(self, question):\n",
    "        question_vec = self.vectorizer.transform([self._preprocess(question)])\n",
    "        similarities = cosine_similarity(question_vec, self.column_vectors)\n",
    "        best_idx = np.argmax(similarities)\n",
    "        return self.columns[best_idx] if similarities[0, best_idx] > 0.3 else None\n",
    "\n",
    "# ========== ADVANCED QUESTION HANDLER ==========\n",
    "class EnhancedQuestionHandler:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.convert_dtypes().infer_objects()\n",
    "        self.column_matcher = SemanticColumnMatcher(df.columns.tolist())\n",
    "        self._preprocess_data()\n",
    "        \n",
    "    def _preprocess_data(self):\n",
    "        # Convert potential date columns\n",
    "        date_cols = [col for col in self.df.columns \n",
    "                    if re.search(r'date|year|month|day', col, re.I)]\n",
    "        for col in date_cols:\n",
    "            self.df[col] = pd.to_datetime(self.df[col], errors='ignore')\n",
    "            \n",
    "        # Enhanced numeric detection\n",
    "        self.numeric_cols = self.df.select_dtypes(include=np.number).columns.tolist()\n",
    "        \n",
    "    def handle(self, question):\n",
    "        try:\n",
    "            if self._is_boolean(question):\n",
    "                return self._handle_boolean(question)\n",
    "            if self._is_list(question):\n",
    "                return self._handle_list(question)\n",
    "            if self._is_aggregate(question):\n",
    "                return self._handle_aggregate(question)\n",
    "            if self._is_comparison(question):\n",
    "                return self._handle_comparison(question)\n",
    "            return self._handle_fallback(question)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error handling question: {question} - {str(e)}\")\n",
    "            return self._handle_fallback(question)\n",
    "\n",
    "    def _is_boolean(self, question):\n",
    "        return re.search(r'\\b(is|are|does|do|was|were|has|have|had|can|could|should|will|would)\\b', \n",
    "                        question, re.I)\n",
    "\n",
    "    def _is_list(self, question):\n",
    "        return re.search(r'\\b(list|top|most|least|unique|first|last)\\b', question, re.I)\n",
    "\n",
    "    def _is_aggregate(self, question):\n",
    "        return re.search(r'\\b(count|sum|total|average|mean|max|min|median|std|deviation|range)\\b', \n",
    "                        question, re.I)\n",
    "\n",
    "    def _is_comparison(self, question):\n",
    "        return re.search(r'\\b(greater|more than|above|less than|below|between|after|before)\\b', \n",
    "                        question, re.I)\n",
    "\n",
    "    def _handle_boolean(self, question):\n",
    "        # Enhanced boolean logic with multi-column support\n",
    "        col = self.column_matcher.best_match(question)\n",
    "        if col:\n",
    "            if re.search(r'\\b(all|every)\\b', question, re.I):\n",
    "                return \"Yes\" if self.df[col].nunique() == 1 else \"No\"\n",
    "            if re.search(r'\\b(any|exists)\\b', question, re.I):\n",
    "                return \"Yes\" if not self.df[col].isnull().all() else \"No\"\n",
    "            \n",
    "            numbers = re.findall(r'\\d+\\.?\\d*', question)\n",
    "            if numbers and col in self.numeric_cols:\n",
    "                value = float(numbers[0])\n",
    "                if re.search(r'\\b(greater|more than|above)\\b', question):\n",
    "                    return \"Yes\" if (self.df[col] > value).any() else \"No\"\n",
    "                if re.search(r'\\b(less than|below)\\b', question):\n",
    "                    return \"Yes\" if (self.df[col] < value).any() else \"No\"\n",
    "                \n",
    "        return \"No\"  # Conservative default\n",
    "\n",
    "    def _handle_list(self, question):\n",
    "        col = self.column_matcher.best_match(question)\n",
    "        if not col:\n",
    "            return None\n",
    "            \n",
    "        # Handle top N queries\n",
    "        n = min([int(num) for num in re.findall(r'\\d+', question)] or [5])\n",
    "        \n",
    "        if re.search(r'\\b(top|highest|most)\\b', question):\n",
    "            if col in self.numeric_cols:\n",
    "                return self.df.nlargest(n, col)[col].tolist()\n",
    "            return self.df[col].value_counts().head(n).index.tolist()\n",
    "            \n",
    "        if re.search(r'\\b(bottom|lowest|least)\\b', question):\n",
    "            if col in self.numeric_cols:\n",
    "                return self.df.nsmallest(n, col)[col].tolist()\n",
    "            return self.df[col].value_counts().tail(n).index.tolist()\n",
    "            \n",
    "        return self.df[col].dropna().unique().tolist()[:n]\n",
    "\n",
    "    def _handle_aggregate(self, question):\n",
    "        col = self.column_matcher.best_match(question)\n",
    "        if not col or col not in self.numeric_cols:\n",
    "            return None\n",
    "            \n",
    "        if re.search(r'\\b(count|number)\\b', question):\n",
    "            return int(self.df[col].count())\n",
    "            \n",
    "        if re.search(r'\\b(sum|total)\\b', question):\n",
    "            return f\"{self.df[col].sum():.2f}\"\n",
    "            \n",
    "        if re.search(r'\\b(average|mean)\\b', question):\n",
    "            return f\"{self.df[col].mean():.2f}\"\n",
    "            \n",
    "        if re.search(r'\\b(median)\\b', question):\n",
    "            return f\"{self.df[col].median():.2f}\"\n",
    "            \n",
    "        if re.search(r'\\b(max|highest)\\b', question):\n",
    "            return f\"{self.df[col].max():.2f}\"\n",
    "            \n",
    "        if re.search(r'\\b(min|lowest)\\b', question):\n",
    "            return f\"{self.df[col].min():.2f}\"\n",
    "            \n",
    "        if re.search(r'\\b(range)\\b', question):\n",
    "            return f\"{self.df[col].max() - self.df[col].min():.2f}\"\n",
    "            \n",
    "        return None\n",
    "\n",
    "    def _handle_comparison(self, question):\n",
    "        # Handle complex comparisons\n",
    "        cols = [self.column_matcher.best_match(q_part) \n",
    "               for q_part in re.split(r'\\b(and|or)\\b', question)]\n",
    "        cols = [c for c in cols if c]\n",
    "        \n",
    "        if len(cols) >= 2 and cols[0] in self.numeric_cols:\n",
    "            numbers = [float(n) for n in re.findall(r'\\d+\\.?\\d*', question)]\n",
    "            if len(numbers) >= 2:\n",
    "                return str(self.df[\n",
    "                    (self.df[cols[0]] > numbers[0]) & \n",
    "                    (self.df[cols[1]] < numbers[1])\n",
    "                ].shape[0])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _handle_fallback(self, question):\n",
    "        # Enhanced context generation for QA model\n",
    "        context = \"\\n\".join([\n",
    "            f\"Column '{col}': {self._describe_column(col)}\"\n",
    "            for col in self.df.columns\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            result = qa_pipeline(question=question, context=context)\n",
    "            return self._postprocess_answer(result['answer'])\n",
    "        except:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    def _describe_column(self, col):\n",
    "        # Generate rich column descriptions\n",
    "        dtype = str(self.df[col].dtype)\n",
    "        sample = self.df[col].dropna().sample(min(3, len(self.df))).tolist()\n",
    "        \n",
    "        if pd.api.types.is_numeric_dtype(self.df[col]):\n",
    "            stats = f\"min: {self.df[col].min():.2f}, max: {self.df[col].max():.2f}, mean: {self.df[col].mean():.2f}\"\n",
    "        else:\n",
    "            stats = f\"{self.df[col].nunique()} unique values\"\n",
    "            \n",
    "        return f\"{dtype} column. Sample values: {sample}. Statistics: {stats}\"\n",
    "\n",
    "    def _postprocess_answer(self, answer):\n",
    "        # Clean up model outputs\n",
    "        answer = re.sub(r'\\s+', ' ', answer).strip()\n",
    "        numbers = re.findall(r'\\d+\\.?\\d*', answer)\n",
    "        return numbers[0] if numbers else answer\n",
    "\n",
    "# ========== OPTIMIZED PROCESSING ==========\n",
    "def process_qa_file(output_filename, file_type, max_rows=None):\n",
    "    qa_df = pd.read_csv(QA_FILE)\n",
    "    if max_rows: qa_df = qa_df.head(max_rows)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for _, row in qa_df.iterrows():\n",
    "        dataset_name = row['dataset']\n",
    "        question = row['question']\n",
    "        \n",
    "        dataset_path = os.path.join(DATA_DIR, dataset_name, f\"{file_type}.csv\")\n",
    "        if not os.path.exists(dataset_path):\n",
    "            predictions.append(\"Dataset not found\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            df = pd.read_csv(dataset_path)\n",
    "            handler = EnhancedQuestionHandler(df)\n",
    "            answer = handler.handle(question)\n",
    "            predictions.append(str(answer))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {dataset_name}: {str(e)}\")\n",
    "            predictions.append(\"Error\")\n",
    "    \n",
    "    # Save with error handling\n",
    "    try:\n",
    "        with open(f\"{output_filename}.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(predictions))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save predictions: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_qa_file(\"predictions\", \"cleaned_all\")\n",
    "    process_qa_file(\"predictions_lite\", \"cleaned_sample\", max_rows=20)\n",
    "    \n",
    "    # Validate file sizes before zipping\n",
    "    if os.path.exists(\"predictions.txt\") and os.path.exists(\"predictions_lite.txt\"):\n",
    "        with zipfile.ZipFile(\"CUET.zip\", \"w\") as zipf:\n",
    "            zipf.write(\"predictions.txt\")\n",
    "            zipf.write(\"predictions_lite.txt\")\n",
    "        print(\"✅ Archive created successfully\")\n",
    "    else:\n",
    "        logging.error(\"Failed to create archive - prediction files missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6524241,
     "sourceId": 10544645,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6573590,
     "sourceId": 10617391,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
